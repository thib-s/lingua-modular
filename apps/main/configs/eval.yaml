name: "debug_evals"
# ckpt_dir: !!CHANGETHIS!!
# dump_dir: !!CHANGETHIS!!
ckpt_dir: /lustre/fswork/projects/rech/reh/ujk81mx/dumps/modular_base/checkpoints/0000038000/
dump_dir: /lustre/fswork/projects/rech/reh/ujk81mx/dumps/modular_base/global_eval/dump/
metric_log_dir: /lustre/fswork/projects/rech/reh/ujk81mx/dumps/modular_base/global_eval/

generator:
  max_tokens: 1024
  dtype: bf16
  temperature: 1.0
  top_p: 0.95
harness:
  log_samples: false
  tasks:
    - hellaswag # ok
    #- task: boolq # ok
    #  dataset_kwargs:
    #    trust_remote_code: true
    ## - task: nq_open # ko
    ##   num_fewshot: 5
    #- piqa
    #- task: social_iqa
    #  dataset_kwargs:
    #    trust_remote_code: true
    # - triviaqa
    - winogrande
    ## - openbookqa
    - arc_easy
    #- arc_challenge
    ## - race
    #- commonsense_qa
    ## - coqa
    #- copa
    ## - gsm8k
    ## - bbh
    - mmlu
    #- mmlu_pro
validation:
  max_steps: 1
